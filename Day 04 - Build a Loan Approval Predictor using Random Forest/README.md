# ğŸ¯ Day 4: Loan Approval Prediction using Random Forest  

## ğŸ“Œ Overview  
In this project, we implement **Loan Approval Prediction** using **Random Forest Classifier**. The goal is to predict whether a loan should be approved based on various applicant attributes such as income, credit history, and loan amount.  

---

## ğŸš€ What You'll Learn  
âœ… Data Preprocessing (Handling Missing Values, Encoding, Feature Scaling)  
âœ… **Random Forest Classifier** for Loan Approval Prediction  
âœ… **Hyperparameter Tuning** using **GridSearchCV**  
âœ… Model Evaluation using **Accuracy, Precision, Recall & F1-score**  
âœ… Confusion Matrix & **ROC AUC** Score Analysis  

---

## ğŸ“‚ Project Structure  
```
Day-4-Loan-Approval-Prediction/
â”‚â”€â”€ README.md  # Documentation  
â”‚â”€â”€ loan_approval.ipynb  # Interactive Notebook  
â”‚â”€â”€ loan_approval.py  # Standalone Python Script  
â”‚â”€â”€ loan_data.csv  # Dataset  
```
---

## ğŸ“Œ Why Both .py and .ipynb?  
This project includes:  

ğŸ“’ **Jupyter Notebook (.ipynb)** â†’ For interactive exploration, visualization, and debugging.  
ğŸ’» **Python Script (.py)** â†’ For direct execution and efficiency.  

---

## ğŸ“Š Dataset  
We use a dataset that contains:  

ğŸ“Œ **Features:** Applicant income, loan amount, credit history, employment status, etc.  
ğŸ¯ **Target Variable:** Loan Status (Approved/Not Approved)  

---

## ğŸ”§ Technologies Used  
ğŸ”¹ Python  
ğŸ”¹ Pandas & NumPy (Data Processing)  
ğŸ”¹ Scikit-learn (ML Models & Evaluation)  
ğŸ”¹ Matplotlib & Seaborn (Visualization)  
ğŸ”¹ Random Forest Classifier  

---

## ğŸ“œ How to Run the Project?  
1ï¸âƒ£ Clone the repository  
```bash
git clone https://github.com/Aadhityan-Senthil/30-Day-Applied-AI-Challenge.git  
cd 30-Day-Applied-AI-Challenge/Day-4-Loan-Approval-Predictor using Random Forest
```
2ï¸âƒ£ Install dependencies  
```bash
pip install -r requirements.txt  
```
3ï¸âƒ£ Run the script  
```bash
python Loan Approval Predictor.py
```
---

## ğŸ“ˆ Results & Analysis  
âœ… **Best Model Performance:**  
ğŸ“Œ **Accuracy:** 92.99%  
ğŸ“Œ **Precision:** 90.01%  
ğŸ“Œ **Recall:** 77.00%  
ğŸ“Œ **F1-score:** 83.00%  
ğŸ“Œ **ROC AUC:** 97.51%  

âœ… **Observations:**  
ğŸ”¹ **Handling missing values improved model performance.**  
ğŸ”¹ **Random Forest provided robust classification with high ROC AUC.**  
ğŸ”¹ **Feature Importance analysis showed that credit history and income were key factors.**  
ğŸ”¹ **Hyperparameter tuning significantly boosted accuracy.**  

---

## ğŸ“Œ Next Steps  
ğŸ”¹ Experiment with **XGBoost or Gradient Boosting** for better results.  
ğŸ”¹ Try **Feature Selection techniques** to improve efficiency.  
ğŸ”¹ Implement **SMOTE (Synthetic Minority Over-sampling)** to handle class imbalance.  

---

## â­ Contribute & Connect!  
ğŸ“¢ Follow my **30-day AI challenge** & share your feedback! ğŸš€ğŸ”¥  
