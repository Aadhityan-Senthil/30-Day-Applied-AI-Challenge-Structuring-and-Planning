# 🎯 Day 4: Loan Approval Prediction using Random Forest  

## 📌 Overview  
In this project, we implement **Loan Approval Prediction** using **Random Forest Classifier**. The goal is to predict whether a loan should be approved based on various applicant attributes such as income, credit history, and loan amount.  

---

## 🚀 What You'll Learn  
✅ Data Preprocessing (Handling Missing Values, Encoding, Feature Scaling)  
✅ **Random Forest Classifier** for Loan Approval Prediction  
✅ **Hyperparameter Tuning** using **GridSearchCV**  
✅ Model Evaluation using **Accuracy, Precision, Recall & F1-score**  
✅ Confusion Matrix & **ROC AUC** Score Analysis  

---

## 📂 Project Structure  
```
Day-4-Loan-Approval-Prediction/
│── README.md  # Documentation  
│── loan_approval.ipynb  # Interactive Notebook  
│── loan_approval.py  # Standalone Python Script  
│── loan_data.csv  # Dataset  
```
---

## 📌 Why Both .py and .ipynb?  
This project includes:  

📒 **Jupyter Notebook (.ipynb)** → For interactive exploration, visualization, and debugging.  
💻 **Python Script (.py)** → For direct execution and efficiency.  

---

## 📊 Dataset  
We use a dataset that contains:  

📌 **Features:** Applicant income, loan amount, credit history, employment status, etc.  
🎯 **Target Variable:** Loan Status (Approved/Not Approved)  

---

## 🔧 Technologies Used  
🔹 Python  
🔹 Pandas & NumPy (Data Processing)  
🔹 Scikit-learn (ML Models & Evaluation)  
🔹 Matplotlib & Seaborn (Visualization)  
🔹 Random Forest Classifier  

---

## 📜 How to Run the Project?  
1️⃣ Clone the repository  
```bash
git clone https://github.com/Aadhityan-Senthil/30-Day-Applied-AI-Challenge.git  
cd 30-Day-Applied-AI-Challenge/Day-4-Loan-Approval-Predictor using Random Forest
```
2️⃣ Install dependencies  
```bash
pip install -r requirements.txt  
```
3️⃣ Run the script  
```bash
python Loan Approval Predictor.py
```
---

## 📈 Results & Analysis  
✅ **Best Model Performance:**  
📌 **Accuracy:** 92.99%  
📌 **Precision:** 90.01%  
📌 **Recall:** 77.00%  
📌 **F1-score:** 83.00%  
📌 **ROC AUC:** 97.51%  

✅ **Observations:**  
🔹 **Handling missing values improved model performance.**  
🔹 **Random Forest provided robust classification with high ROC AUC.**  
🔹 **Feature Importance analysis showed that credit history and income were key factors.**  
🔹 **Hyperparameter tuning significantly boosted accuracy.**  

---

## 📌 Next Steps  
🔹 Experiment with **XGBoost or Gradient Boosting** for better results.  
🔹 Try **Feature Selection techniques** to improve efficiency.  
🔹 Implement **SMOTE (Synthetic Minority Over-sampling)** to handle class imbalance.  

---

## ⭐ Contribute & Connect!  
📢 Follow my **30-day AI challenge** & share your feedback! 🚀🔥  
