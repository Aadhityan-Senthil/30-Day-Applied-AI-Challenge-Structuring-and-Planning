# ğŸ¯ Day 7: Model Comparison using Cross-Validation  

## ğŸ“Œ Overview  
In this project, we evaluate multiple Machine Learning models for classification using **Cross-Validation**. The goal is to compare different models and determine the best-performing one based on accuracy.  

## ğŸš€ What You'll Learn  
âœ… Cross-Validation to assess model performance  
âœ… Implementing multiple classification models (Logistic Regression, Random Forest, SVM, XGBoost, etc.)  
âœ… Hyperparameter Tuning for optimal results  
âœ… Evaluating models using Accuracy Score  
âœ… Identifying the best model for the dataset  

## ğŸ“‚ Project Structure  
```
Day-7-Model-Comparison/
â”‚â”€â”€ README.md  # Documentation  
â”‚â”€â”€ model_comparison.ipynb  # Interactive Notebook  
â”‚â”€â”€ model_comparison.py  # Standalone Python Script  
â”‚â”€â”€ dataset.csv  # Dataset  
```
### ğŸ“Œ Why Both `.py` and `.ipynb`?  
This project includes:  

ğŸ“’ **Jupyter Notebook (.ipynb)** â†’ For interactive exploration, visualization, and debugging.  
ğŸ’» **Python Script (.py)** â†’ For direct execution and efficiency.  

## ğŸ“Š Dataset  
We used a classification dataset to evaluate the models. The dataset consists of:  

ğŸ“Œ **Features**: Multiple independent variables  
ğŸ¯ **Target Variable**: Binary Classification (0 or 1)  

## ğŸ”§ Technologies Used  
ğŸ”¹ Python  
ğŸ”¹ Pandas & NumPy (Data Processing)  
ğŸ”¹ Scikit-learn (ML Models & Evaluation)  
ğŸ”¹ Matplotlib & Seaborn (Visualization)  
ğŸ”¹ XGBoost (Boosting Algorithm)  

## ğŸ“œ How to Run the Project?  
1ï¸âƒ£ Clone the repository:  
```bash
git clone https://github.com/Aadhityan-Senthil/30-Day-Applied-AI-Challenge.git  
cd 30-Day-Applied-AI-Challenge/Day-7-Comparing-all-the-models-used-so-far-using-Cross-vadlidation
```  

2ï¸âƒ£ Install dependencies:  
```bash
pip install -r requirements.txt  
```  

3ï¸âƒ£ Run the script:  
```bash
python Comparing Models.py
```  

## ğŸ“ˆ Results & Analysis  

âœ… **Best Model Performance:** **Random Forest** achieved the highest accuracy.  

### ğŸ”¹ **Model Performance (Mean CV Accuracy Scores):**  
| Model                    | Accuracy |  
|--------------------------|----------|  
| Logistic Regression      | 75.17%    |  
| Random Forest           | 78.44%    |  
| Gradient Boosting       | 78.23%    |  
| Support Vector Machine  | 74.72%    |  
| K-Nearest Neighbors     | 69.58%    |  
| Decision Tree           | 69.80%    |  
| XGBoost                 | 77.24%    |  

âœ… **Observations:**  
ğŸ”¹ **Random Forest performed the best with 78.44% accuracy.**  
ğŸ”¹ Hyperparameter tuning could further improve performance.  
ğŸ”¹ Feature scaling & selection might boost model efficiency.  
ğŸ”¹ Cross-validation ensures robust performance evaluation.  

## ğŸ“Œ Next Steps  
ğŸ”¹ Tune hyperparameters using GridSearchCV.  
ğŸ”¹ Experiment with feature selection techniques.  
ğŸ”¹ Test models on different datasets for generalization.  

## â­ Contribute & Connect!  
ğŸ“¢ Follow my **30-Day AI Challenge** & share your feedback! ğŸš€ğŸ”¥  
